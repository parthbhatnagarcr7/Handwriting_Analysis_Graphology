{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7430d25b-1315-4964-8273-38e1517a434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: label_list found.\n",
      "Classifier 1 was not trained due to insufficient class diversity in training data.\n",
      "Classifier 2 accuracy: 1.0\n",
      "Classifier 3 accuracy: 1.0\n",
      "Classifier 4 accuracy: 1.0\n",
      "Classifier 5 accuracy: 1.0\n",
      "Classifier 6 accuracy: 1.0\n",
      "Classifier 7 accuracy: 1.0\n",
      "Classifier 8 accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter file name to predict or 'z' to exit:  Canvas.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Angle: DESCENDING\n",
      "Top Margin: MEDIUM OR BIGGER\n",
      "Letter Size: SMALL\n",
      "Line Spacing: BIG\n",
      "Word Spacing: BIG\n",
      "Pen Pressure: HEAVY\n",
      "Slant: EXTREMELY RECLINED\n",
      "Mental Energy or Will Power:  [1.]\n",
      "Modesty:  [1.]\n",
      "Personal Harmony and Flexibility:  [0.]\n",
      "Lack of Discipline:  [0.]\n",
      "Poor Concentration:  [0.]\n",
      "Non Communicativeness:  [1.]\n",
      "Social Isolation:  [1.]\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter file name to predict or 'z' to exit:  z\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import itertools\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import extract_v3\n",
    "import categorize\n",
    "import cv2\n",
    "\n",
    "# Initialize lists for features and labels\n",
    "X_baseline_angle = []\n",
    "X_top_margin = []\n",
    "X_letter_size = []\n",
    "X_line_spacing = []\n",
    "X_word_spacing = []\n",
    "X_pen_pressure = []\n",
    "X_slant_angle = []\n",
    "y_t1 = []\n",
    "y_t2 = []\n",
    "y_t3 = []\n",
    "y_t4 = []\n",
    "y_t5 = []\n",
    "y_t6 = []\n",
    "y_t7 = []\n",
    "y_t8 = []\n",
    "page_ids = []\n",
    "\n",
    "label_list_path = r\"C:\\Users\\parth\\OneDrive\\Desktop\\IBM_Work\\Graphology\\Handwriting_Analysis\\label_list\"\n",
    "\n",
    "if os.path.isfile(label_list_path):\n",
    "    print(\"Info: label_list found.\")\n",
    "    with open(label_list_path, \"r\") as labels:\n",
    "        lines = labels.readlines()\n",
    "        for i in range(0, len(lines), 2):\n",
    "            feature_line = lines[i].strip().split()\n",
    "            label_line = lines[i+1].strip().split()\n",
    "            \n",
    "            if len(feature_line) != 8 or len(label_line) != 8:\n",
    "                print(f\"Skipping line pair due to incorrect format: {lines[i].strip()} and {lines[i+1].strip()}\")\n",
    "                continue\n",
    "\n",
    "            X_baseline_angle.append(float(feature_line[0]))\n",
    "            X_top_margin.append(float(feature_line[1]))\n",
    "            X_letter_size.append(float(feature_line[2]))\n",
    "            X_line_spacing.append(float(feature_line[3]))\n",
    "            X_word_spacing.append(float(feature_line[4]))\n",
    "            X_pen_pressure.append(float(feature_line[5]))\n",
    "            X_slant_angle.append(float(feature_line[6]))\n",
    "            page_ids.append(feature_line[7])\n",
    "\n",
    "            y_t1.append(float(label_line[0]))\n",
    "            y_t2.append(float(label_line[1]))\n",
    "            y_t3.append(float(label_line[2]))\n",
    "            y_t4.append(float(label_line[3]))\n",
    "            y_t5.append(float(label_line[4]))\n",
    "            y_t6.append(float(label_line[5]))\n",
    "            y_t7.append(float(label_line[6]))\n",
    "            y_t8.append(float(label_line[7]))\n",
    "\n",
    "    # Create datasets for each trait\n",
    "    X_t1 = list(zip(X_baseline_angle, X_slant_angle))\n",
    "    X_t2 = list(zip(X_letter_size, X_pen_pressure))\n",
    "    X_t3 = list(zip(X_letter_size, X_top_margin))\n",
    "    X_t4 = list(zip(X_line_spacing, X_word_spacing))\n",
    "    X_t5 = list(zip(X_slant_angle, X_top_margin))\n",
    "    X_t6 = list(zip(X_letter_size, X_line_spacing))\n",
    "    X_t7 = list(zip(X_letter_size, X_word_spacing))\n",
    "    X_t8 = list(zip(X_line_spacing, X_word_spacing))\n",
    "\n",
    "    classifiers = []\n",
    "    datasets = [\n",
    "        (X_t1, y_t1),\n",
    "        (X_t2, y_t2),\n",
    "        (X_t3, y_t3),\n",
    "        (X_t4, y_t4),\n",
    "        (X_t5, y_t5),\n",
    "        (X_t6, y_t6),\n",
    "        (X_t7, y_t7),\n",
    "        (X_t8, y_t8),\n",
    "    ]\n",
    "    random_states = [8, 16, 32, 64, 42, 52, 21, 73]\n",
    "\n",
    "    for i, (X, y) in enumerate(datasets):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=random_states[i])\n",
    "        if len(set(y_train)) > 1:  # Ensure there is more than one class\n",
    "            clf = SVC(kernel='rbf')\n",
    "            clf.fit(X_train, y_train)\n",
    "            accuracy = accuracy_score(clf.predict(X_test), y_test)\n",
    "            print(f\"Classifier {i+1} accuracy: {accuracy}\")\n",
    "            classifiers.append(clf)\n",
    "        else:\n",
    "            print(f\"Classifier {i+1} was not trained due to insufficient class diversity in training data.\")\n",
    "            classifiers.append(None)  # Append None to maintain the correct index\n",
    "\n",
    "    # Prediction loop\n",
    "    while True:\n",
    "        file_name = input(\"Enter file name to predict or 'z' to exit: \")\n",
    "        if file_name == 'z':\n",
    "            break\n",
    "\n",
    "        # Construct the full path to the image file\n",
    "        image_path = os.path.join(r'C:\\Users\\parth\\OneDrive\\Desktop\\IBM_Work\\Graphology\\Handwriting_Analysis\\images\\images', file_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            print(f\"Error: Image file '{file_name}' not found or could not be loaded.\")\n",
    "            continue\n",
    "\n",
    "        raw_features = extract_v3.start(image_path)  # Use the correct path\n",
    "\n",
    "        raw_baseline_angle = raw_features[0]\n",
    "        baseline_angle, comment = categorize.determine_baseline_angle(raw_baseline_angle)\n",
    "        print(\"Baseline Angle: \" + comment)\n",
    "\n",
    "        raw_top_margin = raw_features[1]\n",
    "        top_margin, comment = categorize.determine_top_margin(raw_top_margin)\n",
    "        print(\"Top Margin: \" + comment)\n",
    "\n",
    "        raw_letter_size = raw_features[2]\n",
    "        letter_size, comment = categorize.determine_letter_size(raw_letter_size)\n",
    "        print(\"Letter Size: \" + comment)\n",
    "\n",
    "        raw_line_spacing = raw_features[3]\n",
    "        line_spacing, comment = categorize.determine_line_spacing(raw_line_spacing)\n",
    "        print(\"Line Spacing: \" + comment)\n",
    "\n",
    "        raw_word_spacing = raw_features[4]\n",
    "        word_spacing, comment = categorize.determine_word_spacing(raw_word_spacing)\n",
    "        print(\"Word Spacing: \" + comment)\n",
    "\n",
    "        raw_pen_pressure = raw_features[5]\n",
    "        pen_pressure, comment = categorize.determine_pen_pressure(raw_pen_pressure)\n",
    "        print(\"Pen Pressure: \" + comment)\n",
    "\n",
    "        raw_slant_angle = raw_features[6]\n",
    "        slant_angle, comment = categorize.determine_slant_angle(raw_slant_angle)\n",
    "        print(\"Slant: \" + comment)\n",
    "\n",
    "        # Check if each classifier exists before attempting to use it\n",
    "        if classifiers[0]:\n",
    "            print(\"Emotional Stability: \", classifiers[0].predict([[baseline_angle, slant_angle]]))\n",
    "        if classifiers[1]:\n",
    "            print(\"Mental Energy or Will Power: \", classifiers[1].predict([[letter_size, pen_pressure]]))\n",
    "        if classifiers[2]:\n",
    "            print(\"Modesty: \", classifiers[2].predict([[letter_size, top_margin]]))\n",
    "        if classifiers[3]:\n",
    "            print(\"Personal Harmony and Flexibility: \", classifiers[3].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[4]:\n",
    "            print(\"Lack of Discipline: \", classifiers[4].predict([[slant_angle, top_margin]]))\n",
    "        if classifiers[5]:\n",
    "            print(\"Poor Concentration: \", classifiers[5].predict([[letter_size, line_spacing]]))\n",
    "        if classifiers[6]:\n",
    "            print(\"Non Communicativeness: \", classifiers[6].predict([[letter_size, word_spacing]]))\n",
    "        if classifiers[7]:\n",
    "            print(\"Social Isolation: \", classifiers[7].predict([[line_spacing, word_spacing]]))\n",
    "        \n",
    "        print(\"---------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Error: label_list file not found.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc411e-44f8-4e22-999b-a8d0f0047082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: label_list found.\n",
      "Classifier 1 was not trained due to insufficient class diversity in training data.\n",
      "RandomForestClassifier 2 accuracy: 1.0\n",
      "DecisionTreeClassifier 2 accuracy: 1.0\n",
      "KNeighborsClassifier 2 accuracy: 1.0\n",
      "LogisticRegression 2 accuracy: 0.9313725490196079\n",
      "GradientBoostingClassifier 2 accuracy: 1.0\n",
      "AdaBoostClassifier 2 accuracy: 1.0\n",
      "GaussianNB 2 accuracy: 1.0\n",
      "RandomForestClassifier 3 accuracy: 1.0\n",
      "DecisionTreeClassifier 3 accuracy: 1.0\n",
      "KNeighborsClassifier 3 accuracy: 1.0\n",
      "LogisticRegression 3 accuracy: 1.0\n",
      "GradientBoostingClassifier 3 accuracy: 1.0\n",
      "AdaBoostClassifier 3 accuracy: 1.0\n",
      "GaussianNB 3 accuracy: 1.0\n",
      "RandomForestClassifier 4 accuracy: 1.0\n",
      "DecisionTreeClassifier 4 accuracy: 1.0\n",
      "KNeighborsClassifier 4 accuracy: 1.0\n",
      "LogisticRegression 4 accuracy: 0.9901960784313726\n",
      "GradientBoostingClassifier 4 accuracy: 1.0\n",
      "AdaBoostClassifier 4 accuracy: 1.0\n",
      "GaussianNB 4 accuracy: 1.0\n",
      "RandomForestClassifier 5 accuracy: 1.0\n",
      "DecisionTreeClassifier 5 accuracy: 1.0\n",
      "KNeighborsClassifier 5 accuracy: 1.0\n",
      "LogisticRegression 5 accuracy: 1.0\n",
      "GradientBoostingClassifier 5 accuracy: 1.0\n",
      "AdaBoostClassifier 5 accuracy: 1.0\n",
      "GaussianNB 5 accuracy: 1.0\n",
      "RandomForestClassifier 6 accuracy: 1.0\n",
      "DecisionTreeClassifier 6 accuracy: 1.0\n",
      "KNeighborsClassifier 6 accuracy: 1.0\n",
      "LogisticRegression 6 accuracy: 1.0\n",
      "GradientBoostingClassifier 6 accuracy: 1.0\n",
      "AdaBoostClassifier 6 accuracy: 1.0\n",
      "GaussianNB 6 accuracy: 1.0\n",
      "RandomForestClassifier 7 accuracy: 1.0\n",
      "DecisionTreeClassifier 7 accuracy: 1.0\n",
      "KNeighborsClassifier 7 accuracy: 1.0\n",
      "LogisticRegression 7 accuracy: 1.0\n",
      "GradientBoostingClassifier 7 accuracy: 1.0\n",
      "AdaBoostClassifier 7 accuracy: 1.0\n",
      "GaussianNB 7 accuracy: 1.0\n",
      "RandomForestClassifier 8 accuracy: 1.0\n",
      "DecisionTreeClassifier 8 accuracy: 1.0\n",
      "KNeighborsClassifier 8 accuracy: 0.9901960784313726\n",
      "LogisticRegression 8 accuracy: 0.9901960784313726\n",
      "GradientBoostingClassifier 8 accuracy: 1.0\n",
      "AdaBoostClassifier 8 accuracy: 1.0\n",
      "GaussianNB 8 accuracy: 0.9901960784313726\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter file name to predict or 'z' to exit:  000-19.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************************************\n",
      "Slant determined to be straight.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import extract_v3\n",
    "import categorize\n",
    "import cv2\n",
    "\n",
    "# Initialize lists for features and labels\n",
    "X_baseline_angle = []\n",
    "X_top_margin = []\n",
    "X_letter_size = []\n",
    "X_line_spacing = []\n",
    "X_word_spacing = []\n",
    "X_pen_pressure = []\n",
    "X_slant_angle = []\n",
    "y_t1 = []\n",
    "y_t2 = []\n",
    "y_t3 = []\n",
    "y_t4 = []\n",
    "y_t5 = []\n",
    "y_t6 = []\n",
    "y_t7 = []\n",
    "y_t8 = []\n",
    "page_ids = []\n",
    "\n",
    "label_list_path = r\"C:\\Users\\parth\\OneDrive\\Desktop\\IBM_Work\\Graphology\\Handwriting_Analysis\\label_list\"\n",
    "\n",
    "if os.path.isfile(label_list_path):\n",
    "    print(\"Info: label_list found.\")\n",
    "    with open(label_list_path, \"r\") as labels:\n",
    "        lines = labels.readlines()\n",
    "        for i in range(0, len(lines), 2):\n",
    "            feature_line = lines[i].strip().split()\n",
    "            label_line = lines[i+1].strip().split()\n",
    "            \n",
    "            if len(feature_line) != 8 or len(label_line) != 8:\n",
    "                print(f\"Skipping line pair due to incorrect format: {lines[i].strip()} and {lines[i+1].strip()}\")\n",
    "                continue\n",
    "\n",
    "            X_baseline_angle.append(float(feature_line[0]))\n",
    "            X_top_margin.append(float(feature_line[1]))\n",
    "            X_letter_size.append(float(feature_line[2]))\n",
    "            X_line_spacing.append(float(feature_line[3]))\n",
    "            X_word_spacing.append(float(feature_line[4]))\n",
    "            X_pen_pressure.append(float(feature_line[5]))\n",
    "            X_slant_angle.append(float(feature_line[6]))\n",
    "            page_ids.append(feature_line[7])\n",
    "\n",
    "            y_t1.append(float(label_line[0]))\n",
    "            y_t2.append(float(label_line[1]))\n",
    "            y_t3.append(float(label_line[2]))\n",
    "            y_t4.append(float(label_line[3]))\n",
    "            y_t5.append(float(label_line[4]))\n",
    "            y_t6.append(float(label_line[5]))\n",
    "            y_t7.append(float(label_line[6]))\n",
    "            y_t8.append(float(label_line[7]))\n",
    "\n",
    "    # Create datasets for each trait\n",
    "    X_t1 = list(zip(X_baseline_angle, X_slant_angle))\n",
    "    X_t2 = list(zip(X_letter_size, X_pen_pressure))\n",
    "    X_t3 = list(zip(X_letter_size, X_top_margin))\n",
    "    X_t4 = list(zip(X_line_spacing, X_word_spacing))\n",
    "    X_t5 = list(zip(X_slant_angle, X_top_margin))\n",
    "    X_t6 = list(zip(X_letter_size, X_line_spacing))\n",
    "    X_t7 = list(zip(X_letter_size, X_word_spacing))\n",
    "    X_t8 = list(zip(X_line_spacing, X_word_spacing))\n",
    "\n",
    "    classifiers = []\n",
    "    datasets = [\n",
    "        (X_t1, y_t1),\n",
    "        (X_t2, y_t2),\n",
    "        (X_t3, y_t3),\n",
    "        (X_t4, y_t4),\n",
    "        (X_t5, y_t5),\n",
    "        (X_t6, y_t6),\n",
    "        (X_t7, y_t7),\n",
    "        (X_t8, y_t8),\n",
    "    ]\n",
    "    random_states = [8, 16, 32, 64, 42, 52, 21, 73]\n",
    "\n",
    "    for i, (X, y) in enumerate(datasets):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=random_states[i])\n",
    "        if len(set(y_train)) > 1:  # Ensure there is more than one class\n",
    "\n",
    "            # Using RandomForestClassifier\n",
    "            clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf_rf.fit(X_train, y_train)\n",
    "            accuracy_rf = accuracy_score(clf_rf.predict(X_test), y_test)\n",
    "            print(f\"RandomForestClassifier {i+1} accuracy: {accuracy_rf}\")\n",
    "\n",
    "            # Using DecisionTreeClassifier\n",
    "            clf_dt = DecisionTreeClassifier(random_state=42)\n",
    "            clf_dt.fit(X_train, y_train)\n",
    "            accuracy_dt = accuracy_score(clf_dt.predict(X_test), y_test)\n",
    "            print(f\"DecisionTreeClassifier {i+1} accuracy: {accuracy_dt}\")\n",
    "\n",
    "            # Using KNeighborsClassifier\n",
    "            clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "            clf_knn.fit(X_train, y_train)\n",
    "            accuracy_knn = accuracy_score(clf_knn.predict(X_test), y_test)\n",
    "            print(f\"KNeighborsClassifier {i+1} accuracy: {accuracy_knn}\")\n",
    "\n",
    "            # Using LogisticRegression\n",
    "            clf_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "            clf_lr.fit(X_train, y_train)\n",
    "            accuracy_lr = accuracy_score(clf_lr.predict(X_test), y_test)\n",
    "            print(f\"LogisticRegression {i+1} accuracy: {accuracy_lr}\")\n",
    "\n",
    "            # Using GradientBoostingClassifier\n",
    "            clf_gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "            clf_gb.fit(X_train, y_train)\n",
    "            accuracy_gb = accuracy_score(clf_gb.predict(X_test), y_test)\n",
    "            print(f\"GradientBoostingClassifier {i+1} accuracy: {accuracy_gb}\")\n",
    "\n",
    "            # Using AdaBoostClassifier\n",
    "            clf_ab = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "            clf_ab.fit(X_train, y_train)\n",
    "            accuracy_ab = accuracy_score(clf_ab.predict(X_test), y_test)\n",
    "            print(f\"AdaBoostClassifier {i+1} accuracy: {accuracy_ab}\")\n",
    "\n",
    "            # Using GaussianNB\n",
    "            clf_nb = GaussianNB()\n",
    "            clf_nb.fit(X_train, y_train)\n",
    "            accuracy_nb = accuracy_score(clf_nb.predict(X_test), y_test)\n",
    "            print(f\"GaussianNB {i+1} accuracy: {accuracy_nb}\")\n",
    "\n",
    "            classifiers.append((clf_rf, clf_dt, clf_knn, clf_lr, clf_gb, clf_ab, clf_nb))\n",
    "        else:\n",
    "            print(f\"Classifier {i+1} was not trained due to insufficient class diversity in training data.\")\n",
    "            classifiers.append((None, None, None, None, None, None, None))  # Append None to maintain the correct index\n",
    "\n",
    "    # Prediction loop\n",
    "    while True:\n",
    "        file_name = input(\"Enter file name to predict or 'z' to exit: \")\n",
    "        if file_name == 'z':\n",
    "            break\n",
    "\n",
    "        # Construct the full path to the image file\n",
    "        image_path = os.path.join(r'C:\\Users\\parth\\Downloads\\images\\images', file_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            print(f\"Error: Image file '{file_name}' not found or could not be loaded.\")\n",
    "            continue\n",
    "\n",
    "        raw_features = extract_v3.start(image_path)  # Use the correct path\n",
    "\n",
    "        raw_baseline_angle = raw_features[0]\n",
    "        baseline_angle, comment = categorize.determine_baseline_angle(raw_baseline_angle)\n",
    "        print(\"Baseline Angle: \" + comment)\n",
    "\n",
    "        raw_top_margin = raw_features[1]\n",
    "        top_margin, comment = categorize.determine_top_margin(raw_top_margin)\n",
    "        print(\"Top Margin: \" + comment)\n",
    "\n",
    "        raw_letter_size = raw_features[2]\n",
    "        letter_size, comment = categorize.determine_letter_size(raw_letter_size)\n",
    "        print(\"Letter Size: \" + comment)\n",
    "\n",
    "        raw_line_spacing = raw_features[3]\n",
    "        line_spacing, comment = categorize.determine_line_spacing(raw_line_spacing)\n",
    "        print(\"Line Spacing: \" + comment)\n",
    "\n",
    "        raw_word_spacing = raw_features[4]\n",
    "        word_spacing, comment = categorize.determine_word_spacing(raw_word_spacing)\n",
    "        print(\"Word Spacing: \" + comment)\n",
    "\n",
    "        raw_pen_pressure = raw_features[5]\n",
    "        pen_pressure, comment = categorize.determine_pen_pressure(raw_pen_pressure)\n",
    "        print(\"Pen Pressure: \" + comment)\n",
    "\n",
    "        raw_slant_angle = raw_features[6]\n",
    "        slant_angle, comment = categorize.determine_slant_angle(raw_slant_angle)\n",
    "        print(\"Slant: \" + comment)\n",
    "\n",
    "        # Check if each classifier exists before attempting to use it\n",
    "        if classifiers[0][0]:\n",
    "            print(\"Emotional Stability (RF): \", classifiers[0][0].predict([[baseline_angle, slant_angle]]))\n",
    "        if classifiers[0][1]:\n",
    "            print(\"Emotional Stability (DT): \", classifiers[0][1].predict([[baseline_angle, slant_angle]]))\n",
    "        if classifiers[0][2]:\n",
    "            print(\"Emotional Stability (KNN): \", classifiers[0][2].predict([[baseline_angle, slant_angle]]))\n",
    "        if classifiers[0][3]:\n",
    "            print(\"Emotional Stability (LR): \", classifiers[0][3].predict([[baseline_angle, slant_angle]]))\n",
    "        if classifiers[0][4]:\n",
    "            print(\"Emotional Stability (GB): \", classifiers[0][4].predict([[baseline_angle, slant_angle]]))\n",
    "        if classifiers[0][5]:\n",
    "            print(\"Emotional Stability (AB): \", classifiers[0][5].predict([[baseline_angle, slant_angle]]))\n",
    "        if classifiers[0][6]:\n",
    "            print(\"Emotional Stability (NB): \", classifiers[0][6].predict([[baseline_angle, slant_angle]]))\n",
    "\n",
    "        if classifiers[1][0]:\n",
    "            print(\"Mental Energy or Will Power (RF): \", classifiers[1][0].predict([[letter_size, pen_pressure]]))\n",
    "        if classifiers[1][1]:\n",
    "            print(\"Mental Energy or Will Power (DT): \", classifiers[1][1].predict([[letter_size, pen_pressure]]))\n",
    "        if classifiers[1][2]:\n",
    "            print(\"Mental Energy or Will Power (KNN): \", classifiers[1][2].predict([[letter_size, pen_pressure]]))\n",
    "        if classifiers[1][3]:\n",
    "            print(\"Mental Energy or Will Power (LR): \", classifiers[1][3].predict([[letter_size, pen_pressure]]))\n",
    "        if classifiers[1][4]:\n",
    "            print(\"Mental Energy or Will Power (GB): \", classifiers[1][4].predict([[letter_size, pen_pressure]]))\n",
    "        if classifiers[1][5]:\n",
    "            print(\"Mental Energy or Will Power (AB): \", classifiers[1][5].predict([[letter_size, pen_pressure]]))\n",
    "        if classifiers[1][6]:\n",
    "            print(\"Mental Energy or Will Power (NB): \", classifiers[1][6].predict([[letter_size, pen_pressure]]))\n",
    "\n",
    "        if classifiers[2][0]:\n",
    "            print(\"Modesty (RF): \", classifiers[2][0].predict([[letter_size, top_margin]]))\n",
    "        if classifiers[2][1]:\n",
    "            print(\"Modesty (DT): \", classifiers[2][1].predict([[letter_size, top_margin]]))\n",
    "        if classifiers[2][2]:\n",
    "            print(\"Modesty (KNN): \", classifiers[2][2].predict([[letter_size, top_margin]]))\n",
    "        if classifiers[2][3]:\n",
    "            print(\"Modesty (LR): \", classifiers[2][3].predict([[letter_size, top_margin]]))\n",
    "        if classifiers[2][4]:\n",
    "            print(\"Modesty (GB): \", classifiers[2][4].predict([[letter_size, top_margin]]))\n",
    "        if classifiers[2][5]:\n",
    "            print(\"Modesty (AB): \", classifiers[2][5].predict([[letter_size, top_margin]]))\n",
    "        if classifiers[2][6]:\n",
    "            print(\"Modesty (NB): \", classifiers[2][6].predict([[letter_size, top_margin]]))\n",
    "\n",
    "        if classifiers[3][0]:\n",
    "            print(\"Personal Harmony and Flexibility (RF): \", classifiers[3][0].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[3][1]:\n",
    "            print(\"Personal Harmony and Flexibility (DT): \", classifiers[3][1].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[3][2]:\n",
    "            print(\"Personal Harmony and Flexibility (KNN): \", classifiers[3][2].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[3][3]:\n",
    "            print(\"Personal Harmony and Flexibility (LR): \", classifiers[3][3].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[3][4]:\n",
    "            print(\"Personal Harmony and Flexibility (GB): \", classifiers[3][4].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[3][5]:\n",
    "            print(\"Personal Harmony and Flexibility (AB): \", classifiers[3][5].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[3][6]:\n",
    "            print(\"Personal Harmony and Flexibility (NB): \", classifiers[3][6].predict([[line_spacing, word_spacing]]))\n",
    "\n",
    "        if classifiers[4][0]:\n",
    "            print(\"Lack of Discipline (RF): \", classifiers[4][0].predict([[slant_angle, top_margin]]))\n",
    "        if classifiers[4][1]:\n",
    "            print(\"Lack of Discipline (DT): \", classifiers[4][1].predict([[slant_angle, top_margin]]))\n",
    "        if classifiers[4][2]:\n",
    "            print(\"Lack of Discipline (KNN): \", classifiers[4][2].predict([[slant_angle, top_margin]]))\n",
    "        if classifiers[4][3]:\n",
    "            print(\"Lack of Discipline (LR): \", classifiers[4][3].predict([[slant_angle, top_margin]]))\n",
    "        if classifiers[4][4]:\n",
    "            print(\"Lack of Discipline (GB): \", classifiers[4][4].predict([[slant_angle, top_margin]]))\n",
    "        if classifiers[4][5]:\n",
    "            print(\"Lack of Discipline (AB): \", classifiers[4][5].predict([[slant_angle, top_margin]]))\n",
    "        if classifiers[4][6]:\n",
    "            print(\"Lack of Discipline (NB): \", classifiers[4][6].predict([[slant_angle, top_margin]]))\n",
    "\n",
    "        if classifiers[5][0]:\n",
    "            print(\"Poor Concentration (RF): \", classifiers[5][0].predict([[letter_size, line_spacing]]))\n",
    "        if classifiers[5][1]:\n",
    "            print(\"Poor Concentration (DT): \", classifiers[5][1].predict([[letter_size, line_spacing]]))\n",
    "        if classifiers[5][2]:\n",
    "            print(\"Poor Concentration (KNN): \", classifiers[5][2].predict([[letter_size, line_spacing]]))\n",
    "        if classifiers[5][3]:\n",
    "            print(\"Poor Concentration (LR): \", classifiers[5][3].predict([[letter_size, line_spacing]]))\n",
    "        if classifiers[5][4]:\n",
    "            print(\"Poor Concentration (GB): \", classifiers[5][4].predict([[letter_size, line_spacing]]))\n",
    "        if classifiers[5][5]:\n",
    "            print(\"Poor Concentration (AB): \", classifiers[5][5].predict([[letter_size, line_spacing]]))\n",
    "        if classifiers[5][6]:\n",
    "            print(\"Poor Concentration (NB): \", classifiers[5][6].predict([[letter_size, line_spacing]]))\n",
    "\n",
    "        if classifiers[6][0]:\n",
    "            print(\"Non Communicativeness (RF): \", classifiers[6][0].predict([[letter_size, word_spacing]]))\n",
    "        if classifiers[6][1]:\n",
    "            print(\"Non Communicativeness (DT): \", classifiers[6][1].predict([[letter_size, word_spacing]]))\n",
    "        if classifiers[6][2]:\n",
    "            print(\"Non Communicativeness (KNN): \", classifiers[6][2].predict([[letter_size, word_spacing]]))\n",
    "        if classifiers[6][3]:\n",
    "            print(\"Non Communicativeness (LR): \", classifiers[6][3].predict([[letter_size, word_spacing]]))\n",
    "        if classifiers[6][4]:\n",
    "            print(\"Non Communicativeness (GB): \", classifiers[6][4].predict([[letter_size, word_spacing]]))\n",
    "        if classifiers[6][5]:\n",
    "            print(\"Non Communicativeness (AB): \", classifiers[6][5].predict([[letter_size, word_spacing]]))\n",
    "        if classifiers[6][6]:\n",
    "            print(\"Non Communicativeness (NB): \", classifiers[6][6].predict([[letter_size, word_spacing]]))\n",
    "\n",
    "        if classifiers[7][0]:\n",
    "            print(\"Social Isolation (RF): \", classifiers[7][0].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[7][1]:\n",
    "            print(\"Social Isolation (DT): \", classifiers[7][1].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[7][2]:\n",
    "            print(\"Social Isolation (KNN): \", classifiers[7][2].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[7][3]:\n",
    "            print(\"Social Isolation (LR): \", classifiers[7][3].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[7][4]:\n",
    "            print(\"Social Isolation (GB): \", classifiers[7][4].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[7][5]:\n",
    "            print(\"Social Isolation (AB): \", classifiers[7][5].predict([[line_spacing, word_spacing]]))\n",
    "        if classifiers[7][6]:\n",
    "            print(\"Social Isolation (NB): \", classifiers[7][6].predict([[line_spacing, word_spacing]]))\n",
    "        \n",
    "        print(\"---------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Error: label_list file not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6aedf7-91ea-47a9-9134-00582b5bf9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
